---
version: '3'

tasks:
  deploy-infrastructure:
    desc: 'Deploy hybrid infrastructure'
    cmds:
      - ctlptl apply -f Cluster.yaml
      - helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
      - helm repo update
      - |
        helm upgrade --install \
          --create-namespace \
          --namespace kube-system \
          --set controller.progressDeadlineSeconds=500 \
          --version 4.14.0 \
          --wait \
          ingress-nginx ingress-nginx/ingress-nginx
      - echo "ðŸš€ Hybrid infrastructure deployed successfully!"

  deploy-ollama:
    desc: 'Deploy deepseek-r1:1.5b with Ollama'
    cmds:
      - kubectl create namespace ollama -o yaml --dry-run=client | kubectl apply -f -
      - kubectl apply -f ollama/
      - kubectl -n ollama rollout status deployment ollama
      - echo "ðŸ¤– Ollama with deepseek model deployed successfully!"

  watch-ollama-download:
    desc: 'Watch download progress'
    cmds:
      - kubectl -n ollama logs deployments/ollama -c ollama-model-puller -f
      - echo "ðŸ‘€ Watching Ollama model download progress..."

  deploy-inference-gateway:
    desc: 'Deploy inference-gateway with hybrid providers'
    cmds:
      - |
        helm upgrade --install \
          --create-namespace \
          --namespace inference-gateway \
          --set ingress.enabled=true \
          --set config.OLLAMA_API_URL="http://ollama.ollama:8080/v1" \
          --set envFrom.secretRef=inference-gateway \
          --version 0.19.5 \
          --wait \
          inference-gateway oci://ghcr.io/inference-gateway/charts/inference-gateway
      - echo "ðŸšª Inference Gateway with hybrid providers deployed successfully!"

  clean:
    desc: 'Clean up the cluster'
    cmds:
      - ctlptl delete -f Cluster.yaml
      - echo "ðŸ§¹ Cluster cleaned up successfully!"
