---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-gateway
  namespace: inference-gateway
  labels:
    app: inference-gateway
spec:
  selector:
    matchLabels:
      app: inference-gateway
  template:
    metadata:
      labels:
        app: inference-gateway
    spec:
      serviceAccountName: inference-gateway
      containers:
        - name: inference-gateway
          image: ghcr.io/inference-gateway/inference-gateway:v0.1.10
          ports:
            - containerPort: 8080
          resources:
            requests:
              memory: 32Mi
              cpu: 50m
            limits:
              memory: 64Mi
              cpu: 100m
          envFrom:
            - configMapRef:
                name: inference-gateway
            - secretRef:
                name: inference-gateway
          startupProbe:
            httpGet:
              path: /health
              port: 8080
            failureThreshold: 30
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            periodSeconds: 15
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
          imagePullPolicy: Always
